{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGsW6jEz8pZvJ06mlKGxF9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frank-Dg/Paper-Information-Parser/blob/main/parser_paper_info.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFwcfAV7Ea02"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 设置目标URL\n",
        "url = 'https://proceedings.neurips.cc/paper_files/paper/2022'\n",
        "\n",
        "# 发送HTTP GET请求\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()  # 确保请求成功\n",
        "\n",
        "# 使用BeautifulSoup解析HTML内容\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# 假设论文标题是在一些特定的HTML标签内，你需要根据实际的HTML结构来调整选择器\n",
        "# 例如，如果论文标题在<h1>或<h2>标签内，可以使用soup.find_all('h1')或soup.find_all('h2')\n",
        "papers_soup = soup.find_all('li', class_='conference')\n",
        "titles=[]\n",
        "urls=[]\n",
        "authors=[]\n",
        "for paper_soup in papers_soup:\n",
        "    # 获取论文标题，它在<a>标签的title属性中\n",
        "    title = paper_soup.find('a').text\n",
        "    # 获取论文的URL路径，它在<a>标签的href属性中\n",
        "    href = paper_soup.find('a').get('href')\n",
        "    # 获取作者信息，它在<i>标签内\n",
        "    author = paper_soup.find('i').text\n",
        "\n",
        "    # print(f\"Title: {title}\")\n",
        "    titles.append(title)\n",
        "    #print(f\"URL: https://proceedings.neurips.cc{href}\")\n",
        "    #print('https://proceedings.neurips.cc'+href)\n",
        "    urls.append('https://proceedings.neurips.cc'+href)\n",
        "    # print(f\"Authors: {authors}\\n\")\n",
        "    authors.append(author)\n",
        "data = {\n",
        "    'Title': titles,\n",
        "    'URL': urls,\n",
        "    'Authors': authors\n",
        "}\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 导出到Excel文件\n",
        "excel_file = 'NeurIPS2022_Papers.xlsx'\n",
        "df.to_excel(excel_file, index=False, engine='openpyxl')\n",
        "\n",
        "print(f'论文信息已保存到 {excel_file}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qrmamFDEqqK",
        "outputId": "e70a0cc6-ed68-4c3d-81ea-dd8f98030276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "论文信息已保存到 NeurIPS2022_Papers.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 假设urls是包含论文详细页面链接的列表\n",
        "urls = df['URL'].tolist()  # 如果你已经有了DataFrame\n",
        "\n",
        "# 用于存储论文标题和摘要的列表\n",
        "papers_info = []\n",
        "\n",
        "\n",
        "for url in urls:\n",
        "    # 发送请求\n",
        "    response = requests.get(url)\n",
        "    # 如果响应状态码为200，即请求成功\n",
        "    if response.status_code == 200:\n",
        "        # 解析HTML内容\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        # 找到标题和摘要\n",
        "        # 这里假设标题是在第一个<h4>标签，摘要是在跟随\"Abstract\"的第一个<p>标签里\n",
        "        title = soup.find('h4').text.strip()\n",
        "        abstract_tag = soup.find('h4', text='Abstract').find_next('p')\n",
        "        abstract = abstract_tag.text.strip() if abstract_tag else 'No abstract available'\n",
        "        # 将提取的信息添加到列表中\n",
        "        #print(abstract)\n",
        "        papers_info.append({'Title': title, 'Abstract': abstract})\n",
        "    else:\n",
        "        print(f\"Failed to fetch {url}\")\n",
        "\n",
        "# 将结果转换为DataFrame\n",
        "df_papers_info = pd.DataFrame(papers_info)\n",
        "# 显示前几项数据以检查\n",
        "print(df_papers_info.head())\n",
        "\n",
        "# 保存到Excel文件\n",
        "df_papers_info.to_excel(\"NeurIPS2022_Papers_Abstracts.xlsx\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVHxN8zRPb8W",
        "outputId": "81182b7f-5fc5-4618-f14b-8f22b6f8dc06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-6c888ca04f43>:18: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  abstract_tag = soup.find('h4', text='Abstract').find_next('p')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Title  \\\n",
            "0  Federated Submodel Optimization for Hot and Co...   \n",
            "1  On Kernelized Multi-Armed Bandits with Constra...   \n",
            "2       Geometric Order Learning for Rank Estimation   \n",
            "3  Structured Recognition for Generative Models w...   \n",
            "4  Fast Bayesian Coresets via Subsampling and Qua...   \n",
            "\n",
            "                                            Abstract  \n",
            "0  We focus on federated learning in practical re...  \n",
            "1  We study a stochastic bandit problem with a ge...  \n",
            "2  A novel approach to rank estimation, called ge...  \n",
            "3  A key goal of unsupervised learning is to go b...  \n",
            "4  Bayesian coresets approximate a posterior dist...  \n"
          ]
        }
      ]
    }
  ]
}